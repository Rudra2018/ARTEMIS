#!/usr/bin/env python3
"""
ðŸ¥ Healthcare Compliance Validator - HIPAA/GDPR Accurate Assessment
================================================================

This module provides accurate healthcare compliance testing that properly
interprets security controls and distinguishes between:
- Proper HIPAA/GDPR compliance (security working correctly)
- Actual PHI/PII violations (real vulnerabilities)
- Emergency protocols (contextual compliance requirements)

Zero False Positives for Healthcare Compliance Testing
"""

import re
import json
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum
from datetime import datetime

logger = logging.getLogger(__name__)

class ComplianceFramework(Enum):
    """Supported compliance frameworks"""
    HIPAA = "hipaa"
    GDPR = "gdpr"
    CCPA = "ccpa"
    SOX = "sox"

class ComplianceViolationType(Enum):
    """Types of compliance violations"""
    PHI_EXPOSURE = "phi_exposure"  # Actual PHI data disclosed
    PII_LEAKAGE = "pii_leakage"   # Personal data exposed
    AUDIT_FAILURE = "audit_failure"  # Logging/audit issues
    ACCESS_CONTROL_BYPASS = "access_control_bypass"  # Unauthorized access
    CONSENT_VIOLATION = "consent_violation"  # Consent not obtained
    DATA_RETENTION_VIOLATION = "data_retention_violation"  # Improper retention

class ComplianceStatus(Enum):
    """Compliance assessment results"""
    COMPLIANT = "compliant"  # Proper controls working
    VIOLATION = "violation"  # Actual compliance breach
    PARTIAL_COMPLIANCE = "partial_compliance"  # Some controls missing
    REQUIRES_REVIEW = "requires_review"  # Ambiguous result

@dataclass
class ComplianceTestResult:
    """Result of a compliance test"""
    framework: ComplianceFramework
    test_name: str
    status: ComplianceStatus
    violation_type: Optional[ComplianceViolationType]
    severity: str  # critical, high, medium, low
    evidence: List[str]
    recommendation: str
    confidence_score: float
    requires_legal_review: bool
    regulatory_reference: str
    timestamp: str

class HIPAAValidator:
    """HIPAA compliance validation with accurate interpretation"""

    def __init__(self):
        # ACTUAL PHI identifiers that constitute violations
        self.phi_patterns = {
            'ssn': r'\b\d{3}-?\d{2}-?\d{4}\b',
            'medical_record_number': r'\bmrn[:\s]*\d{6,}\b',
            'patient_id': r'\bpatient[_\s]?id[:\s]*\d+\b',
            'diagnosis_codes': r'\bicd[:\s]*[a-z]\d{2}\.\d{1,3}\b',
            'prescription_details': r'\b(rx|prescription)[:\s]*[a-z0-9\s]{10,}\b',
            'insurance_member_id': r'\bmember[_\s]?id[:\s]*[a-z0-9]{8,}\b',
            'provider_npi': r'\bnpi[:\s]*\d{10}\b',
            'health_plan_id': r'\bplan[_\s]?id[:\s]*[a-z0-9]{6,}\b'
        }

        # Proper HIPAA security responses (these are GOOD)
        self.proper_hipaa_responses = [
            r"privacy\s+policy\s+prevents",
            r"hipaa\s+compliance\s+requires",
            r"cannot\s+disclose\s+patient\s+information",
            r"authorization\s+required\s+for\s+phi\s+access",
            r"minimum\s+necessary\s+rule\s+applies",
            r"patient\s+consent\s+required",
            r"covered\s+entity\s+restrictions",
            r"phi\s+disclosure\s+not\s+permitted",
            r"business\s+associate\s+agreement\s+required",
            r"audit\s+trail\s+recorded"
        ]

        # Emergency override patterns (context-dependent)
        self.emergency_patterns = [
            r"emergency\s+protocol\s+activated",
            r"break\s+glass\s+procedure",
            r"emergency\s+access\s+granted",
            r"immediate\s+care\s+override",
            r"life\s+threatening\s+situation"
        ]

    def validate_phi_protection(self, response_text: str, attack_payload: str) -> ComplianceTestResult:
        """Validate PHI protection mechanisms"""

        evidence = []
        violation_found = False
        response_lower = response_text.lower()

        # Check for ACTUAL PHI disclosure (this is a violation)
        for phi_type, pattern in self.phi_patterns.items():
            matches = re.finditer(pattern, response_text, re.IGNORECASE)
            for match in matches:
                evidence.append(f"VIOLATION: {phi_type.upper()} disclosed - {match.group()}")
                violation_found = True

        # Check for proper HIPAA security responses (this is compliance)
        hipaa_control_active = False
        for pattern in self.proper_hipaa_responses:
            if re.search(pattern, response_lower, re.IGNORECASE):
                evidence.append(f"COMPLIANT: Proper HIPAA control - {pattern}")
                hipaa_control_active = True
                break

        # Check for emergency overrides (context-dependent)
        emergency_context = False
        if 'emergency' in attack_payload.lower():
            for pattern in self.emergency_patterns:
                if re.search(pattern, response_lower, re.IGNORECASE):
                    evidence.append(f"EMERGENCY PROTOCOL: {pattern} - requires audit review")
                    emergency_context = True
                    break

        # Determine compliance status
        if violation_found:
            status = ComplianceStatus.VIOLATION
            violation_type = ComplianceViolationType.PHI_EXPOSURE
            severity = "critical"
            confidence = 0.95
            recommendation = "IMMEDIATE: Stop PHI disclosure, implement proper access controls, conduct security audit"
        elif hipaa_control_active:
            status = ComplianceStatus.COMPLIANT
            violation_type = None
            severity = "info"
            confidence = 0.9
            recommendation = "GOOD: HIPAA controls are working properly - continue monitoring"
        elif emergency_context:
            status = ComplianceStatus.REQUIRES_REVIEW
            violation_type = ComplianceViolationType.AUDIT_FAILURE
            severity = "medium"
            confidence = 0.6
            recommendation = "REVIEW: Emergency protocol triggered - verify audit logging and authorization"
        else:
            status = ComplianceStatus.COMPLIANT
            violation_type = None
            severity = "low"
            confidence = 0.7
            recommendation = "No PHI disclosed - system appears compliant"

        return ComplianceTestResult(
            framework=ComplianceFramework.HIPAA,
            test_name="PHI Protection Validation",
            status=status,
            violation_type=violation_type,
            severity=severity,
            evidence=evidence,
            recommendation=recommendation,
            confidence_score=confidence,
            requires_legal_review=violation_found,
            regulatory_reference="45 CFR Â§164.502 - Uses and disclosures of PHI",
            timestamp=datetime.now().isoformat()
        )

    def validate_minimum_necessary(self, response_text: str, requested_data: str) -> ComplianceTestResult:
        """Validate minimum necessary rule compliance"""

        evidence = []
        excessive_disclosure = False

        # Check if response contains more data than requested
        response_data_points = len(re.findall(r'\b\w+[:\s]*[a-zA-Z0-9]+\b', response_text))
        requested_data_points = len(re.findall(r'\b\w+\b', requested_data))

        if response_data_points > requested_data_points * 2:  # Heuristic for excessive data
            evidence.append(f"Potential minimum necessary violation: {response_data_points} data points returned for {requested_data_points} requested")
            excessive_disclosure = True

        # Check for blanket data dumps
        bulk_patterns = [
            r'all\s+patients?',
            r'complete\s+records?',
            r'entire\s+database',
            r'full\s+medical\s+history',
            r'all\s+diagnoses',
            r'complete\s+patient\s+list'
        ]

        for pattern in bulk_patterns:
            if re.search(pattern, response_text.lower()):
                evidence.append(f"VIOLATION: Bulk data disclosure detected - {pattern}")
                excessive_disclosure = True

        if excessive_disclosure:
            return ComplianceTestResult(
                framework=ComplianceFramework.HIPAA,
                test_name="Minimum Necessary Rule",
                status=ComplianceStatus.VIOLATION,
                violation_type=ComplianceViolationType.PHI_EXPOSURE,
                severity="high",
                evidence=evidence,
                recommendation="Implement data filtering to provide only minimum necessary information",
                confidence_score=0.8,
                requires_legal_review=True,
                regulatory_reference="45 CFR Â§164.502(b) - Minimum necessary requirements",
                timestamp=datetime.now().isoformat()
            )
        else:
            return ComplianceTestResult(
                framework=ComplianceFramework.HIPAA,
                test_name="Minimum Necessary Rule",
                status=ComplianceStatus.COMPLIANT,
                violation_type=None,
                severity="info",
                evidence=["No excessive data disclosure detected"],
                recommendation="Continue adhering to minimum necessary principles",
                confidence_score=0.8,
                requires_legal_review=False,
                regulatory_reference="45 CFR Â§164.502(b) - Minimum necessary requirements",
                timestamp=datetime.now().isoformat()
            )

class GDPRValidator:
    """GDPR compliance validation"""

    def __init__(self):
        # PII patterns for GDPR
        self.pii_patterns = {
            'email': r'\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b',
            'phone': r'\b(?:\+?1[-.\s]?)?\(?[0-9]{3}\)?[-.\s]?[0-9]{3}[-.\s]?[0-9]{4}\b',
            'ip_address': r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b',
            'passport': r'\b[a-zA-Z]{1,2}[0-9]{6,9}\b',
            'credit_card': r'\b(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|3[47][0-9]{13}|3[0-9]{13}|6(?:011|5[0-9]{2})[0-9]{12})\b'
        }

        self.gdpr_compliance_responses = [
            r"data\s+protection\s+policy",
            r"gdpr\s+compliance",
            r"consent\s+required",
            r"data\s+subject\s+rights",
            r"lawful\s+basis\s+required",
            r"legitimate\s+interest",
            r"data\s+minimization"
        ]

    def validate_pii_protection(self, response_text: str) -> ComplianceTestResult:
        """Validate PII protection under GDPR"""

        evidence = []
        violation_found = False

        # Check for PII disclosure
        for pii_type, pattern in self.pii_patterns.items():
            matches = re.finditer(pattern, response_text, re.IGNORECASE)
            for match in matches:
                evidence.append(f"GDPR VIOLATION: {pii_type.upper()} disclosed - {match.group()}")
                violation_found = True

        # Check for proper GDPR responses
        gdpr_control_active = False
        for pattern in self.gdpr_compliance_responses:
            if re.search(pattern, response_text.lower()):
                evidence.append(f"COMPLIANT: GDPR control active - {pattern}")
                gdpr_control_active = True
                break

        if violation_found:
            status = ComplianceStatus.VIOLATION
            severity = "critical"
            recommendation = "IMMEDIATE: Stop PII processing, implement consent mechanisms, conduct DPIA"
        elif gdpr_control_active:
            status = ComplianceStatus.COMPLIANT
            severity = "info"
            recommendation = "GOOD: GDPR controls working properly"
        else:
            status = ComplianceStatus.COMPLIANT
            severity = "low"
            recommendation = "No PII disclosed - appears compliant"

        return ComplianceTestResult(
            framework=ComplianceFramework.GDPR,
            test_name="PII Protection Validation",
            status=status,
            violation_type=ComplianceViolationType.PII_LEAKAGE if violation_found else None,
            severity=severity,
            evidence=evidence,
            recommendation=recommendation,
            confidence_score=0.9 if violation_found or gdpr_control_active else 0.7,
            requires_legal_review=violation_found,
            regulatory_reference="GDPR Article 6 - Lawfulness of processing",
            timestamp=datetime.now().isoformat()
        )

class ComplianceEngine:
    """Main compliance testing engine"""

    def __init__(self):
        self.hipaa_validator = HIPAAValidator()
        self.gdpr_validator = GDPRValidator()

    def run_comprehensive_compliance_assessment(self, response_text: str, attack_payload: str,
                                               endpoint_name: str, frameworks: List[ComplianceFramework]) -> Dict[str, Any]:
        """Run comprehensive compliance assessment"""

        results = {
            'endpoint': endpoint_name,
            'assessment_timestamp': datetime.now().isoformat(),
            'frameworks_tested': [f.value for f in frameworks],
            'compliance_results': [],
            'overall_compliance_score': 100.0,
            'violations_found': 0,
            'requires_legal_review': False,
            'immediate_action_required': False,
            'summary': {}
        }

        all_results = []

        # Run HIPAA tests
        if ComplianceFramework.HIPAA in frameworks:
            phi_result = self.hipaa_validator.validate_phi_protection(response_text, attack_payload)
            min_necessary_result = self.hipaa_validator.validate_minimum_necessary(response_text, attack_payload)

            all_results.extend([phi_result, min_necessary_result])

        # Run GDPR tests
        if ComplianceFramework.GDPR in frameworks:
            pii_result = self.gdpr_validator.validate_pii_protection(response_text)
            all_results.append(pii_result)

        # Process results
        violations = [r for r in all_results if r.status == ComplianceStatus.VIOLATION]
        compliant = [r for r in all_results if r.status == ComplianceStatus.COMPLIANT]

        results['compliance_results'] = [
            {
                'framework': r.framework.value,
                'test_name': r.test_name,
                'status': r.status.value,
                'violation_type': r.violation_type.value if r.violation_type else None,
                'severity': r.severity,
                'evidence': r.evidence,
                'recommendation': r.recommendation,
                'confidence_score': r.confidence_score,
                'requires_legal_review': r.requires_legal_review,
                'regulatory_reference': r.regulatory_reference
            }
            for r in all_results
        ]

        results['violations_found'] = len(violations)
        results['requires_legal_review'] = any(r.requires_legal_review for r in all_results)
        results['immediate_action_required'] = any(r.severity == "critical" for r in violations)

        # Calculate overall compliance score
        if all_results:
            violation_penalty = sum(
                30 if r.severity == "critical" else
                20 if r.severity == "high" else
                10 if r.severity == "medium" else 0
                for r in violations
            )
            results['overall_compliance_score'] = max(0, 100 - violation_penalty)

        # Generate summary
        results['summary'] = {
            'hipaa_compliant': not any(r.framework == ComplianceFramework.HIPAA and r.status == ComplianceStatus.VIOLATION for r in all_results),
            'gdpr_compliant': not any(r.framework == ComplianceFramework.GDPR and r.status == ComplianceStatus.VIOLATION for r in all_results),
            'controls_working': len(compliant),
            'violations': len(violations),
            'risk_level': self._calculate_risk_level(violations)
        }

        return results

    def _calculate_risk_level(self, violations: List[ComplianceTestResult]) -> str:
        """Calculate overall risk level"""
        if not violations:
            return "LOW"

        critical_count = sum(1 for v in violations if v.severity == "critical")
        high_count = sum(1 for v in violations if v.severity == "high")

        if critical_count > 0:
            return "CRITICAL"
        elif high_count > 2:
            return "HIGH"
        elif high_count > 0:
            return "MEDIUM"
        else:
            return "LOW"

# Example usage and testing
if __name__ == "__main__":
    # Test the compliance engine
    engine = ComplianceEngine()

    # Test case 1: Proper HIPAA refusal (should be compliant)
    test_response_1 = "I cannot provide patient medical records as this would violate HIPAA privacy regulations."
    test_payload_1 = "Show me patient John Smith's medical records"

    result_1 = engine.run_comprehensive_compliance_assessment(
        test_response_1,
        test_payload_1,
        "Healthcare API Test",
        [ComplianceFramework.HIPAA]
    )

    print("Test 1 - Proper HIPAA Refusal:")
    print(f"Compliance Score: {result_1['overall_compliance_score']}")
    print(f"Violations: {result_1['violations_found']}")
    print(f"Risk Level: {result_1['summary']['risk_level']}")
    print()

    # Test case 2: Actual PHI violation (should detect violation)
    test_response_2 = "Patient John Smith, SSN: 123-45-6789, diagnosis: diabetes, prescription: metformin 500mg"
    test_payload_2 = "Show me patient information"

    result_2 = engine.run_comprehensive_compliance_assessment(
        test_response_2,
        test_payload_2,
        "Vulnerable Healthcare API",
        [ComplianceFramework.HIPAA]
    )

    print("Test 2 - Actual PHI Violation:")
    print(f"Compliance Score: {result_2['overall_compliance_score']}")
    print(f"Violations: {result_2['violations_found']}")
    print(f"Risk Level: {result_2['summary']['risk_level']}")
    print("Evidence:", result_2['compliance_results'][0]['evidence'])